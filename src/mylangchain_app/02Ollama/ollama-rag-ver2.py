import streamlit as st
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_experimental.text_splitter import SemanticChunker
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_ollama import ChatOllama
from langchain.prompts import ChatPromptTemplate
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# =====================
#  UI ìŠ¤íƒ€ì¼ ì„¤ì •
# =====================
PRIMARY_COLOR = "#1E90FF"
SECONDARY_COLOR = "#FF6347"
BACKGROUND_COLOR = "#F5F5F5"
TEXT_COLOR = "#333333"
SUCCESS_COLOR = "#DFF2BF"
INFO_COLOR = "#BDE5F8"

st.markdown(
    f"""
    <style>
    .stApp {{
        background-color: {BACKGROUND_COLOR};
        color: {TEXT_COLOR};
    }}
    .stButton>button {{
        background-color: {PRIMARY_COLOR};
        color: white;
        border-radius: 5px;
        border: none;
        padding: 10px 20px;
        font-size: 16px;
    }}
    .stTextInput>div>div>input {{
        border: 2px solid {PRIMARY_COLOR};
        border-radius: 5px;
        padding: 10px;
        font-size: 16px;
    }}
    .stFileUploader>div>div>div>button {{
        background-color: {SECONDARY_COLOR};
        color: white;
        border-radius: 5px;
        border: none;
        padding: 10px 20px;
        font-size: 16px;
    }}
    .stAlert-success {{
        background-color: {SUCCESS_COLOR} !important;
        color: {TEXT_COLOR} !important;
        font-weight: bold !important;
        padding: 10px;
        border-radius: 5px;
    }}
    .stAlert-info {{
        background-color: {INFO_COLOR} !important;
        color: {TEXT_COLOR} !important;
        font-weight: bold !important;
        padding: 10px;
        border-radius: 5px;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)

# =====================
#  RAG ì‹œìŠ¤í…œ ì„¤ì •
# =====================
MODEL_NAME = "deepseek-r1:1.5b"
SEARCH_K = 3
TEMP_PDF_PATH = "uploaded_document.pdf"

SYSTEM_PROMPT = (
    "Answer the question with reference to the given context. "
    "If you don't know the answer, just say 'I don't know' and don't make up your own answer. "
    "Please write your answer concisely, with a maximum of 3 sentences. "
    "Please write your final answer in Korean (Korean) without fail. "
    "Context: {context}"
)

# =====================
#  Streamlit UI
# =====================
st.title("DeepSeek R1 & Ollama ê¸°ë°˜ RAG ì‹œìŠ¤í…œ")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“„ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file and "rag_chain" not in st.session_state:
    try:
        with st.spinner(" PDF íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘..."):
            # PDF ë¡œë“œ
            with open(TEMP_PDF_PATH, "wb") as f:
                f.write(uploaded_file.getvalue())
            loader = PDFPlumberLoader(TEMP_PDF_PATH)
            docs = loader.load()

            # ë¬¸ì„œ ë¶„í• 
            embedder = HuggingFaceEmbeddings()
            text_splitter = SemanticChunker(embedder)
            documents = text_splitter.split_documents(docs)

            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            vector_store = FAISS.from_documents(documents, embedder)
            retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": SEARCH_K})

            # LLM ë° ì²´ì¸ êµ¬ì„±
            llm = ChatOllama(model=MODEL_NAME)
            prompt = ChatPromptTemplate.from_messages([("system", SYSTEM_PROMPT), ("human", "{input}")])
            combine_docs_chain = create_stuff_documents_chain(llm, prompt)
            st.session_state.rag_chain = create_retrieval_chain(retriever, combine_docs_chain)

            st.markdown('<p class="stAlert-success"> PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.</p>', unsafe_allow_html=True)
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.text_input(" PDFì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_input and "rag_chain" in st.session_state:
    with st.spinner(" ë‹µë³€ ìƒì„± ì¤‘..."):
        try:
            response = st.session_state.rag_chain.invoke({"input": user_input})
            st.subheader(" ì‘ë‹µ:")
            st.write(response.get("answer", " ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
elif not uploaded_file:
    st.markdown('<p class="stAlert-info"> ì§„í–‰í•˜ë ¤ë©´ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.</p>', unsafe_allow_html=True)
