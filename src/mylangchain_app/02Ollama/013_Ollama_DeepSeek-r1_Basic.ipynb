{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬 Ollama로 설치한 deepseek-r1:1.5b 모델을 사용하기\n",
    "##### ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1 모델을 로드\n",
    "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Q: {question}\\nA:\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 질문을 입력하고 모델의 응답을 받음\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# 결과 출력\n",
    "print(type(response))\n",
    "print(response)\n",
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최신버전 LangChain에서는 ChatOllama와 RunnableSequence(prompt | llm) 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='<think>\\nOkay, the user just asked \"What is Python?\" I need to explain it properly.\\n\\nFirst, I should mention that it\\'s a programming language. Then, I\\'ll define it as a versatile, general-purpose language. It\\'s used for many things like web development, data analysis, and more.\\n\\nI should also note that it\\'s an open-source language, which means the community works on its improvements and extensions.\\n\\nIt would be good to give some examples of common uses in daily life—like using it for tasks at work or studying.\\n\\nFinally, I\\'ll summarize that Python is a programming language with extensive libraries and frameworks available.\\n</think>\\n\\nPython is a popular computer programming language that runs on the Python programming language runtime and is widely used. It was created by Guido van Rosendam and became a public domain language in 1994 after being made publically available under the MIT License.\\n\\n### Definition\\nA **programming language** is a formal language designed to enable computers to perform specific tasks. Python is written in Python and can be used to create scripts, applications, user interfaces, and more. It\\'s widely used across various fields because of its versatility and readability.\\n\\n### Features of Python\\n- **High-level**: Python allows direct interaction with other data types, which makes it easier for programmers.\\n- **Simplicity**: Despite being high-level, Python is relatively simple to use compared to lower-level languages like C++ or Java.\\n- **Extensive library support**: Python has a large number of libraries and modules available on the internet that add functionality to the language. These include the standard library (e.g., `collections`, `random`, `sys`), third-party libraries, and custom-written code.\\n\\n### Common Uses\\nPython is used in many different ways:\\n- **Web development**: Using frameworks like Flask or Django.\\n- **Data analysis**: With tools like Pandas, NumPy, and Matplotlib.\\n- **Machine learning**: Using libraries like Scikit-learn for models.\\n- **User interfaces**: Creating apps with PyQt6 or Tkinter.\\n\\n### Common Names\\nPython is also referred to as \"open source\" because it\\'s the result of a community-driven project. The term *open source* comes from the idea that any part of it can be modified and made available for free.\\n\\n### Summary\\nIn summary, Python is a high-level programming language that runs on its own interpreter or in environments like Virtual.js or Vite. It\\'s widely used because of its flexibility, extensive library support, and ease of use.' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-09-19T06:33:05.5944003Z', 'done': True, 'done_reason': 'stop', 'total_duration': 32918697100, 'load_duration': 2301378800, 'prompt_eval_count': 24, 'prompt_eval_duration': 629960800, 'eval_count': 516, 'eval_duration': 29985600300, 'model_name': 'deepseek-r1:1.5b'} id='run--377393ae-ed09-4082-b0b7-8b5de9218d02-0' usage_metadata={'input_tokens': 24, 'output_tokens': 516, 'total_tokens': 540}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# prompt_template = PromptTemplate.from_template(\"Q: {question}\\nA:\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is Pyhon?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
