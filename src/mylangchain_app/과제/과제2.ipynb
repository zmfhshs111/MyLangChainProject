{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê´€ì‹¬ ë¶„ì•¼: \"ìŒì‹\"\n",
      "ì¶”ì²œ ë¦¬ìŠ¤íŠ¸: ['ì „ì£¼í•œì˜¥ë§ˆì„ ë§›ì§‘íˆ¬ì–´', 'ì„œìš¸ ê´‘ì¥ì‹œì¥ ì¡±ë°œê³¨ëª©', 'ë¶€ì‚° ìê°ˆì¹˜ì‹œì¥ í™œì–´íšŒ', 'ì œì£¼ í‘ë¼ì§€ êµ¬ì´', 'ì „ë‚¨ ëª©í¬ ì‚¼í¬ë„¤ í•´ì¥êµ­']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ğŸ‘‡ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤!\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    "        model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "    output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    template = \"\"\"\n",
    "    ë‹¹ì‹ ì€ í•œêµ­ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê´€ì‹¬ ë¶„ì•¼ì™€ ê´€ë ¨ëœ í•œêµ­ì˜ ìœ ëª…í•œ ì¥ì†Œë‚˜ í™œë™ 5ê°€ì§€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "    {format_instructions}\n",
    "\n",
    "    ê´€ì‹¬ ë¶„ì•¼: {topic}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    topic = \"ìŒì‹\"\n",
    "    result = chain.invoke({\"topic\": topic})\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"ê´€ì‹¬ ë¶„ì•¼: \\\"{topic}\\\"\")\n",
    "    print(\"ì¶”ì²œ ë¦¬ìŠ¤íŠ¸:\", result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¦¬ë·°: \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤.\"\n",
      "ë¶„ì„ ê²°ê³¼: ë¶€ì •\n",
      "\n",
      "ë¦¬ë·°: \"ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ í›Œë¥­í•˜ê³  ìŠ¤í† ë¦¬ë„ ê°ë™ì ì´ì—ˆì–´ìš”!\"\n",
      "ë¶„ì„ ê²°ê³¼: ê¸ì •\n",
      "\n",
      "ë¦¬ë·°: \"ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì˜ì§€ë„ ì¢‹ì§€ë„ ì•Šì•„ìš”.\"\n",
      "ë¶„ì„ ê²°ê³¼: ë³´í†µ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ğŸ‘‡ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤!\n",
    "from langchain.output_parsers import EnumOutputParser\n",
    "from enum import Enum\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ Enum í´ë˜ìŠ¤ ì •ì˜\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ë³´í†µ\"\n",
    "\n",
    "try:\n",
    "    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    "        model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "    output_parser = EnumOutputParser(enum=Sentiment)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    template = \"\"\"\n",
    "    ë‹¹ì‹ ì€ ì˜í™” ë¦¬ë·°ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¦¬ë·°ì˜ ê°ì •ì„ \"ê¸ì •\", \"ë¶€ì •\", \"ë³´í†µ\" ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n",
    "    {format_instructions}\n",
    "\n",
    "    ì˜í™” ë¦¬ë·°:\n",
    "    {review}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ ë¦¬ë·°\n",
    "    reviews = [\n",
    "        \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì–´ìš”. ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤.\",\n",
    "        \"ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ í›Œë¥­í•˜ê³  ìŠ¤í† ë¦¬ë„ ê°ë™ì ì´ì—ˆì–´ìš”!\",\n",
    "        \"ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì˜ì§€ë„ ì¢‹ì§€ë„ ì•Šì•„ìš”.\"\n",
    "    ]\n",
    "\n",
    "    # ê° ë¦¬ë·°ì— ëŒ€í•´ ì²´ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "    for review in reviews:\n",
    "        result = chain.invoke({\"review\": review})\n",
    "        print(f\"ë¦¬ë·°: \\\"{review}\\\"\")\n",
    "        print(f\"ë¶„ì„ ê²°ê³¼: {result.value}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìê¸°ì†Œê°œ: \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¹€ë¯¼ìˆ˜ì´ê³  22ì‚´ì…ë‹ˆë‹¤. ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ìˆì–´ìš”. ì·¨ë¯¸ë¡œëŠ” ê²Œì„í•˜ê¸°, ì˜í™”ë³´ê¸°, ì½”ë”©ì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì•ìœ¼ë¡œ í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\n",
      "\n",
      "ì¶”ì¶œëœ ì •ë³´:\n",
      "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: BaseModel.model_dump_json() got an unexpected keyword argument 'ensure_ascii'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#2-3\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# ì¶”ì¶œí•  ì •ë³´ì— ëŒ€í•œ Pydantic ëª¨ë¸ ì •ì˜\n",
    "class StudentInfo(BaseModel):\n",
    "    name: str = Field(description=\"í•™ìƒì˜ ì´ë¦„\")\n",
    "    age: int = Field(description=\"í•™ìƒì˜ ë‚˜ì´\")\n",
    "    major: str = Field(description=\"í•™ìƒì˜ ì „ê³µ\")\n",
    "    hobbies: List[str] = Field(description=\"í•™ìƒì˜ ì·¨ë¯¸ ë¦¬ìŠ¤íŠ¸\")\n",
    "    goal: str = Field(description=\"í•™ìƒì˜ ëª©í‘œ\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"), \n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "    # ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "    output_parser = PydanticOutputParser(pydantic_object=StudentInfo)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    template = \"\"\"\n",
    "    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ìê¸°ì†Œê°œ í…ìŠ¤íŠ¸ì—ì„œ í•™ìƒì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "    ì•„ë˜ í˜•ì‹ì— ë§ê²Œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
    "    {format_instructions}\n",
    "\n",
    "    ìê¸°ì†Œê°œ:\n",
    "    {introduction}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # ì˜ˆì‹œ ìê¸°ì†Œê°œ\n",
    "    introduction = \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¹€ë¯¼ìˆ˜ì´ê³  22ì‚´ì…ë‹ˆë‹¤. ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ìˆì–´ìš”. ì·¨ë¯¸ë¡œëŠ” ê²Œì„í•˜ê¸°, ì˜í™”ë³´ê¸°, ì½”ë”©ì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì•ìœ¼ë¡œ í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    result = chain.invoke({\"introduction\": introduction})\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"ìê¸°ì†Œê°œ: \\\"{introduction}\\\"\")\n",
    "    print(\"\\nì¶”ì¶œëœ ì •ë³´:\")\n",
    "    print(result.model_dump_json(indent=4, ensure_ascii=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—¬í–‰ í›„ê¸°: \"ì§€ë‚œ ì£¼ì— ë¶€ì‚°ìœ¼ë¡œ 2ë°• 3ì¼ ì—¬í–‰ì„ ë‹¤ë…€ì™”ì–´ìš”. ì´ 30ë§Œì› ì •ë„ ì¼ëŠ”ë° í•´ìš´ëŒ€ì—ì„œ ë°”ë‹¤êµ¬ê²½í•˜ê³ , ìê°ˆì¹˜ì‹œì¥ì—ì„œ íšŒ ë¨¹ê³ , ê°ì²œë¬¸í™”ë§ˆì„ë„ êµ¬ê²½í–ˆì–´ìš”. ì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì—¬í–‰ì´ì—ˆìŠµë‹ˆë‹¤. 5ì  ë§Œì ì— 4ì  ì •ë„ ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.\"\n",
      "\n",
      "ì¶”ì¶œëœ ì •ë³´:\n",
      "{\n",
      "    \"destination\": \"ë¶€ì‚°\",\n",
      "    \"duration\": \"2ë°• 3ì¼\",\n",
      "    \"budget\": \"30ë§Œì›\",\n",
      "    \"rating\": \"4ì \",\n",
      "    \"activities\": \"í•´ìš´ëŒ€ ë°”ë‹¤êµ¬ê²½, ìê°ˆì¹˜ì‹œì¥ íšŒ ë¨¹ê¸°, ê°ì²œë¬¸í™”ë§ˆì„ êµ¬ê²½\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"), \n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "    # ì¶”ì¶œí•  ì •ë³´ì˜ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"destination\", description=\"ì—¬í–‰ì§€\"),\n",
    "        ResponseSchema(name=\"duration\", description=\"ì—¬í–‰ ê¸°ê°„ (ì˜ˆ: 2ë°• 3ì¼)\"),\n",
    "        ResponseSchema(name=\"budget\", description=\"ì´ ì˜ˆì‚°\"),\n",
    "        ResponseSchema(name=\"rating\", description=\"ì¶”ì²œë„ (1-5ì )\"),\n",
    "        ResponseSchema(name=\"activities\", description=\"ì£¼ìš” í™œë™ ë¦¬ìŠ¤íŠ¸ (ì½¤ë§ˆë¡œ êµ¬ë¶„)\")\n",
    "    ]\n",
    "\n",
    "    # ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    template = \"\"\"\n",
    "    ë‹¹ì‹ ì€ ì—¬í–‰ í›„ê¸° í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "    ì•„ë˜ í˜•ì‹ì— ë§ê²Œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
    "    {format_instructions}\n",
    "\n",
    "    ì—¬í–‰ í›„ê¸°:\n",
    "    {review}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # ì˜ˆì‹œ ì—¬í–‰ í›„ê¸°\n",
    "    review = \"ì§€ë‚œ ì£¼ì— ë¶€ì‚°ìœ¼ë¡œ 2ë°• 3ì¼ ì—¬í–‰ì„ ë‹¤ë…€ì™”ì–´ìš”. ì´ 30ë§Œì› ì •ë„ ì¼ëŠ”ë° í•´ìš´ëŒ€ì—ì„œ ë°”ë‹¤êµ¬ê²½í•˜ê³ , ìê°ˆì¹˜ì‹œì¥ì—ì„œ íšŒ ë¨¹ê³ , ê°ì²œë¬¸í™”ë§ˆì„ë„ êµ¬ê²½í–ˆì–´ìš”. ì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì—¬í–‰ì´ì—ˆìŠµë‹ˆë‹¤. 5ì  ë§Œì ì— 4ì  ì •ë„ ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.\"\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    result = chain.invoke({\"review\": review})\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    import json\n",
    "    print(f\"ì—¬í–‰ í›„ê¸°: \\\"{review}\\\"\\n\")\n",
    "    print(\"ì¶”ì¶œëœ ì •ë³´:\")\n",
    "    # ë³´ê¸° ì¢‹ê²Œ json í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "    print(json.dumps(result, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-Iks1ennk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
