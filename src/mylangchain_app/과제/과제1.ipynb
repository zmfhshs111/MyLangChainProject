{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "# Groq playground에서 발급 받은 키를 사용하여 초기화 합니다.\n",
    "# https://console.groq.com/keys\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(\"{ingredients} 재료를 사용하여 만들 수 있는 요리 레시피를 추천해주세요.\")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행 및 결과 출력\n",
    "ingredients = \"토마토, 양파, 치즈\"\n",
    "recipe = chain.invoke({\"ingredients\": ingredients})\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 1단계 프롬프트 및 체인\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{destination}의 대표적인 관광 명소 한 가지를 추천해주세요.\")\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 2단계 프롬프트 및 체인\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{attraction}에 대한 상세한 정보를 알려주세요. (역사, 특징, 방문 팁 등)\")\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "# 두 체인 연결\n",
    "# RunnablePassthrough를 사용하여 1단계 출력을 2단계 입력으로 전달\n",
    "# itemgetter를 사용하지 않고도 동일한 기능 구현\n",
    "combined_chain = {\"attraction\": chain1} | RunnablePassthrough.assign(details=chain2)\n",
    "\n",
    "\n",
    "# 체인 실행 및 결과 출력\n",
    "destination = \"로마\"\n",
    "result = combined_chain.invoke({\"destination\": destination})\n",
    "\n",
    "print(f\"입력: \\\"{destination}\\\"\")\n",
    "print(f\"1단계 결과: \\\"{result['attraction']}\\\"\")\n",
    "print(f\"2단계 결과: 명소: {result['attraction']}\\n{result['details']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 예시 데이터\n",
    "examples = [\n",
    "    {\n",
    "        \"news\": \"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. 이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, 세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\",\n",
    "        \"keywords\": \"삼성전자, 인공지능, 엔비디아\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. 전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\",\n",
    "        \"keywords\": \"세계보건기구, 건강위기, 국제협력\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"대한민국 축구 국가대표팀이 월드컵 예선에서 강력한 상대를 만나 승리하며 본선 진출에 한 걸음 더 다가섰다. 손흥민 선수의 활약이 돋보였다.\",\n",
    "        \"keywords\": \"축구, 월드컵, 손흥민\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 프롬프트\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{news}\"),\n",
    "    (\"ai\", \"키워드: {keywords}\")\n",
    "])\n",
    "\n",
    "# Few-Shot 프롬프트\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 최종 프롬프트\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 기사에서 핵심 키워드 3개를 추출하는 전문가입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 테스트 뉴스\n",
    "test_news = \"제미나이 2.0 플래시는 현재 구글 AI 스튜디오(Google AI Studio) 및 버텍스 AI(Vertex AI)에서 제미나이 API를 통해 개발자에게 실험 모델로 제공됩니다. 모든 개발자는 멀티모달 입력 및 텍스트 출력을 사용할 수 있으며, 텍스트 음성 변환(text-to-speech) 및 네이티브 이미지 생성은 일부 파트너들을 대상으로 제공됩니다. 내년 1월에는 더 많은 모델 사이즈와 함께 일반에 공개될 예정입니다.\"\n",
    "\n",
    "# 체인 실행 및 결과 출력\n",
    "keywords = chain.invoke({\"input\": test_news})\n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-Iks1ennk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
