{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162f569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "문제 4-1: LangChain Tool Calling 시작\n",
      "==============================\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: gsk_xTuE********************************************hIFP. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# db 저장 경로는 노트북 파일 기준이므로, 프로젝트 루트에 저장되도록 경로 수정\u001b[39;00m\n\u001b[32m     50\u001b[39m db_path = \u001b[33m'\u001b[39m\u001b[33m../../db/cafe_db\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m db = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m db.save_local(db_path)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m벡터 DB가 \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m 폴더에 성공적으로 저장되었습니다.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:837\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    835\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    590\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    483\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-Iks1ennk-py3.12\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: gsk_xTuE********************************************hIFP. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "## 공통 설정 및 라이브러리 임포트\n",
    "##############################################################################\n",
    "import os\n",
    "import re\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.tools import tool\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import (AIMessage, BaseMessage, HumanMessage,\n",
    "                                      ToolMessage)\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "##############################################################################\n",
    "## 문제 4-1: 카페 메뉴 도구(Tool) 호출 체인 구현 (LangChain 사용)\n",
    "##############################################################################\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"문제 4-1: LangChain Tool Calling 시작\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# --- 1. 환경변수 설정 및 벡터 DB 구축 ---\n",
    "\n",
    "# .env 파일에서 API 키를 로드합니다.\n",
    "# 이 파일은 프로젝트 최상위 폴더에 위치해야 합니다.\n",
    "load_dotenv()\n",
    "\n",
    "# [!!] 만약 .env 파일이 계속 문제를 일으킨다면, 아래 코드의 주석을 풀고 직접 키를 입력하세요.\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-여기에_실제_API_키를_입력하세요\"\n",
    "# os.environ['TAVILY_API_KEY'] = \"tvly-여기에_실제_API_키를_입력하세요\"\n",
    "\n",
    "\n",
    "# 텍스트 파일 로드 및 분할 (경로 수정!)\n",
    "# '과제' 폴더에서 한 단계 위로 올라가 'data' 폴더로 접근\n",
    "loader = TextLoader('../data/cafe_menu.txt', encoding='utf-8')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 임베딩 모델 로드 및 벡터 DB 생성/저장\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# db 저장 경로는 노트북 파일 기준이므로, 프로젝트 루트에 저장되도록 경로 수정\n",
    "db_path = '../../db/cafe_db'\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(db_path)\n",
    "print(f\"벡터 DB가 '{db_path}' 폴더에 성공적으로 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# --- 2. 도구 정의 및 LLM 바인딩 ---\n",
    "\n",
    "# a) Tavily 웹 검색 도구\n",
    "tavily_search_func = TavilySearchResults(max_results=1, name=\"tavily_search\")\n",
    "\n",
    "# b) 위키피디아 요약 도구\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"위키피디아에서 정보를 검색하고 그 결과를 요약합니다. 커피 역사, 음료 제조법 등 일반적인 지식에 사용됩니다.\"\"\"\n",
    "    wikipedia = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=2000)\n",
    "    return wikipedia.run(query)\n",
    "\n",
    "# c) 로컬 카페 메뉴 DB 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"로컬 카페 메뉴 데이터베이스에서 메뉴의 가격, 재료, 설명 등의 정보를 검색합니다.\"\"\"\n",
    "    vector_db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 1})\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return docs[0].page_content if docs else \"관련 메뉴 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "# 도구 리스트 정의\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools)\n",
    "print(\"3개의 도구가 LLM에 성공적으로 바인딩되었습니다.\")\n",
    "\n",
    "\n",
    "# --- 3. 도구 호출 체인 구현 및 테스트 ---\n",
    "\n",
    "def run_tool_chain(user_input: str):\n",
    "    \"\"\"사용자 질문에 따라 적절한 도구를 호출하는 체인\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=user_input)])\n",
    "    if not response.tool_calls:\n",
    "        return response.content\n",
    "    tool_outputs = []\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        print(f\"Tool Calling: '{tool_name}' with args: {tool_call['args']}\")\n",
    "        if tool_name == \"tavily_search\":\n",
    "            output = tavily_search_func.invoke(tool_call[\"args\"][\"query\"])\n",
    "        elif tool_name == \"wiki_summary\":\n",
    "            output = wiki_summary.invoke(tool_call[\"args\"][\"query\"])\n",
    "        elif tool_name == \"db_search_cafe_func\":\n",
    "            output = db_search_cafe_func.invoke(tool_call[\"args\"][\"query\"])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "        tool_outputs.append(ToolMessage(content=str(output), tool_call_id=tool_call[\"id\"]))\n",
    "    final_response = llm.invoke([HumanMessage(content=user_input), response] + tool_outputs)\n",
    "    return final_response.content\n",
    "\n",
    "question = \"아메리카노의 가격과 특징은 무엇인가요?\"\n",
    "answer = run_tool_chain(question)\n",
    "print(f\"\\n[질문]: {question}\")\n",
    "print(f\"[답변]: {answer}\")\n",
    "print(\"\\n문제 4-1 실행 완료\\n\")\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "## 문제 4-2: 조건부 분기가 있는 메뉴 추천 시스템 (LangGraph 사용)\n",
    "##############################################################################\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"문제 4-2: LangGraph 메뉴 추천 시스템 시작\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# --- 1. 상태 정의 및 노드(기능) 구현 ---\n",
    "\n",
    "class CafeState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "\n",
    "def extract_menu_info(doc_content: str) -> dict:\n",
    "    menu_name_match = re.search(r'\\d+\\.\\s*(.+)', doc_content)\n",
    "    menu_name = menu_name_match.group(1).strip() if menu_name_match else '이름 정보 없음'\n",
    "    price_match = re.search(r'가격:\\s*(.+)', doc_content)\n",
    "    price = price_match.group(1).strip() if price_match else \"가격 정보 없음\"\n",
    "    description_match = re.search(r'설명:\\s*(.+)', doc_content, re.DOTALL)\n",
    "    description = description_match.group(1).strip() if description_match else \"설명 없음\"\n",
    "    return {\"name\": menu_name, \"price\": price, \"description\": description}\n",
    "\n",
    "menu_db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "print(f\"'{db_path}'의 벡터 DB를 성공적으로 재사용합니다.\")\n",
    "\n",
    "def classify_question_node(state: CafeState):\n",
    "    user_message = state[\"messages\"][-1].content.lower()\n",
    "    if \"가격\" in user_message or \"얼마\" in user_message:\n",
    "        return \"price_inquiry\"\n",
    "    elif \"추천\" in user_message or \"어떤\" in user_message or \"마실\" in user_message:\n",
    "        return \"recommendation_request\"\n",
    "    else:\n",
    "        return \"menu_inquiry\"\n",
    "\n",
    "def price_info_node(state: CafeState):\n",
    "    docs = menu_db.similarity_search(\"모든 메뉴의 가격\", k=10)\n",
    "    response_text = \"카페 메뉴 전체 가격 정보입니다:\\n\\n\"\n",
    "    for doc in docs:\n",
    "        info = extract_menu_info(doc.page_content)\n",
    "        response_text += f\"- {info['name']}: {info['price']}\\n\"\n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "def recommend_menu_node(state: CafeState):\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    docs = menu_db.similarity_search(user_message, k=3)\n",
    "    if not docs:\n",
    "        docs = menu_db.similarity_search(\"인기 메뉴\", k=3)\n",
    "    response_text = \"이런 메뉴는 어떠신가요? ☕\\n\\n\"\n",
    "    for doc in docs:\n",
    "        info = extract_menu_info(doc.page_content)\n",
    "        response_text += f\"**{info['name']}**: {info['description']}\\n\"\n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "def menu_info_node(state: CafeState):\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    docs = menu_db.similarity_search(user_message, k=1)\n",
    "    if docs:\n",
    "        info = extract_menu_info(docs[0].page_content)\n",
    "        response_text = f\"**{info['name']}**\\n- **가격**: {info['price']}\\n- **설명**: {info['description']}\"\n",
    "    else:\n",
    "        response_text = \"죄송합니다, 요청하신 메뉴 정보를 찾을 수 없습니다.\"\n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "# --- 2. 그래프 생성 및 실행 ---\n",
    "\n",
    "graph_builder = StateGraph(CafeState)\n",
    "graph_builder.add_node(\"price_inquiry\", price_info_node)\n",
    "graph_builder.add_node(\"recommendation_request\", recommend_menu_node)\n",
    "graph_builder.add_node(\"menu_inquiry\", menu_info_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"__start__\",\n",
    "    classify_question_node,\n",
    "    {\n",
    "        \"price_inquiry\": \"price_inquiry\",\n",
    "        \"recommendation_request\": \"recommendation_request\",\n",
    "        \"menu_inquiry\": \"menu_inquiry\",\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"price_inquiry\", END)\n",
    "graph_builder.add_edge(\"recommendation_request\", END)\n",
    "graph_builder.add_edge(\"menu_inquiry\", END)\n",
    "app = graph_builder.compile()\n",
    "print(\"LangGraph 애플리케이션이 성공적으로 컴파일되었습니다.\")\n",
    "\n",
    "test_questions = [\n",
    "    \"자몽 허니 블랙티에 대해 알려줘\",\n",
    "    \"메뉴 전체 가격이 어떻게 되나요?\",\n",
    "    \"달달하고 시원한 음료 추천해 줄래?\",\n",
    "    \"카푸치노는 얼마야?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\n--- 질문: {q} ---\")\n",
    "    result = app.invoke({\"messages\": [HumanMessage(content=q)]})\n",
    "    print(result['messages'][-1].content)\n",
    "    \n",
    "print(\"\\n문제 4-2 실행 완료\")\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-Iks1ennk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
