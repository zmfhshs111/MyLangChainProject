{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_fSXtdh\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "# 콤마로 구분된 리스트 출력 파서 초기화\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 출력 형식 지침 가져오기\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# OpenAI 모델 설정\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 체인 생성\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# \"AI 관련 기술\"에 대한 체인 호출 실행\n",
    "result = chain.invoke({\"subject\": \"AI 관련 기술\"})\n",
    "\n",
    "# 쉼표로 구분된 리스트 출력\n",
    "print(\"AI 관련 기술 목록:\")\n",
    "print(result)\n",
    "\n",
    "# 결과 활용 예시: CSV 파일로 저장\n",
    "csv_filename = \"../data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI 기술\"])  # 헤더 추가\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' 파일로 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON 출력 파서 초기화\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿을 설정합니다.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 과학 분야 전문가 AI입니다. 질문에 대해 체계적이고 간결한 답변을 JSON 형식으로 제공하세요.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON 출력 형식 지침을 프롬프트에 적용\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# OpenAI 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하는 체인 생성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 질문 설정 (우주 탐사 관련 질문)\n",
    "question = \"최근 10년간 진행된 주요 우주 탐사 미션 3가지를 알려주세요. \\\n",
    "각 미션의 이름은 `mission_name`에, 목표는 `goal`에, 주관 기관은 `agency`에 담아 주세요.\"\n",
    "\n",
    "# 체인 실행 및 JSON 응답 받기\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON 데이터 출력\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "# Titanic 데이터셋 로드\n",
    "df = pd.read_csv('../data/titanic.csv')\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Pandas DataFrame Output Parser 설정\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# 형식 지침 출력\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(\"Format Instructions:\\n\", format_instructions)\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 모델 응답 받기\n",
    "try:\n",
    "    # **Name 열을 표시하십시오.**\n",
    "    print('Name 컬럼 출력')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **첫번째 행을 표시하십시오.**\n",
    "    print('첫번째 행 출력')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "    #Please tell me the average value of the Fare column.\n",
    "    print('Farre 컬럼의 평균값 출력')\n",
    "    df_query3 = \"Show me the average value of the Fare column.\"\n",
    "\n",
    "    parser_output3 = chain.invoke({\"query\": df_query3})\n",
    "    print(parser_output3)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 응답 스키마 정의 [{},{},{}]\n",
    "response_schemas = [\n",
    "    #ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "    ResponseSchema(name=\"data\", description=\"테이블 행을 나타내는 딕셔너리들의 리스트\"),\n",
    "]\n",
    "\n",
    "# Output Parser 설정\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    당신은 테이블 형태의 데이터를 생성하는 AI 어시스턴트입니다(You are an AI assistant that generates tabular data).\n",
    "    반드시 다음 스키마를 따르는 JSON 형식으로 데이터를 반환해야 합니다(You must return the data in JSON format that follows this schema):\n",
    "\n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 체인 생성 (프롬프트 → 모델 → StructuredOutputParser)\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 실행 함수\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # 모델 호출\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "\n",
    "        # 모델이 반환한 JSON을 Pandas DataFrame으로 변환\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # 결과 출력\n",
    "        print(\"\\n Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [예제 1] 2024년 상반기 서울 아파트 평균 매매 가격 데이터 생성\n",
    "print('2024년 상반기 서울 아파트 평균 매매 가격 데이터 생성')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    #\"Create a dataset of the average apartment sale prices in Seoul for the first half of 2024 with columns: District (구), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    "    \"2024년 상반기 서울 아파트 평균 매매가격 데이터셋을 생성해주세요. 컬럼은 다음과 같습니다: 구(District), 평균가격_억원(Average_Price_100M_KRW), 거래건수(Transactions), 전년동기대비증감률_퍼센트(YoY_Change_Percent). 서울의 25개 구에 대한 현실적인 데이터를 생성해주세요.\"\n",
    ")\n",
    "df_seoul_housing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2024년 서울 지하철역별 유동 인구 데이터')\n",
    "# [예제 2] 2024년 서울 지하철역별 유동 인구 데이터\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    #\"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    "    \"2024년 서울 지하철 승객 이용량이 가장 많은 상위 10개 역의 데이터셋을 생성해주세요. 컬럼은 다음과 같습니다: 역명(Station_Name), 호선(Line_Number), 일평균승객수_만명(Daily_Passengers_10K), 평일대주말비율(Weekday_Weekend_Ratio). 실제 서울 지하철의 주요 역들을 기반으로 현실적인 데이터를 생성해주세요.\"\n",
    ")\n",
    "\n",
    "#if df_seoul_subway is not None:\n",
    "df_seoul_subway.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seoul_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('한국 5대 편의점 브랜드별 2024년 매출 및 점포 수')\n",
    "# [예제 3] 한국 5대 편의점 브랜드별 2024년 매출 및 점포 수\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    #\"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    "    \"2024년 한국의 편의점 브랜드 상위 5개사 데이터셋을 생성해주세요. 컬럼은 다음과 같습니다: 브랜드명(Brand_Name), 점포수(Store_Count), 총매출_조원(Revenue_Trillion_KRW), 시장점유율_퍼센트(Market_Share_Percent). CU, GS25, 세븐일레븐, 이마트24, 미니스톱 등 실제 한국 편의점 브랜드를 기반으로 현실적인 데이터를 생성해주세요.\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
