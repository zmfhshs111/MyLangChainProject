{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-1.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n",
      "응답: 파이썬에서 리스트를 정렬하는 방법은 여러 가지가 있습니다.  어떤 방법을 사용할지는 리스트의 내용과 정렬 기준에 따라 달라집니다.  자세히 알아보겠습니다.\n",
      "\n",
      "**1. `list.sort()` 메서드:**\n",
      "\n",
      "* **리스트 자체를 변경합니다.**  새로운 리스트를 반환하지 않고 원본 리스트를 직접 정렬합니다.\n",
      "* **반환값은 `None`입니다.**\n",
      "* **`key` 인자:**  정렬 기준을 지정할 수 있습니다.  `key` 인자에는 정렬 기준을 정의하는 함수를 넣습니다.  예를 들어, 문자열 리스트를 길이 순으로 정렬하려면 `key=len`을 사용합니다.\n",
      "* **`reverse` 인자:**  내림차순 정렬을 원할 경우 `reverse=True`를 사용합니다.\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬 (기본값)\n",
      "my_list.sort()\n",
      "print(f\"오름차순 정렬: {my_list}\")  # 출력: 오름차순 정렬: [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "\n",
      "# 내림차순 정렬\n",
      "my_list.sort(reverse=True)\n",
      "print(f\"내림차순 정렬: {my_list}\")  # 출력: 내림차순 정렬: [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "\n",
      "\n",
      "words = [\"banana\", \"apple\", \"kiwi\", \"orange\"]\n",
      "\n",
      "# 길이 순으로 정렬\n",
      "words.sort(key=len)\n",
      "print(f\"길이 순 정렬: {words}\")  # 출력: 길이 순 정렬: ['kiwi', 'apple', 'banana', 'orange']\n",
      "\n",
      "\n",
      "# 객체 리스트 정렬 (객체의 특정 속성 기준)\n",
      "class Person:\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "\n",
      "people = [Person(\"Alice\", 30), Person(\"Bob\", 25), Person(\"Charlie\", 35)]\n",
      "people.sort(key=lambda person: person.age) # age 속성으로 정렬\n",
      "print(f\"나이 순 정렬: {[person.name for person in people]}\") # 출력: 나이 순 정렬: ['Bob', 'Alice', 'Charlie']\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "**2. `sorted()` 함수:**\n",
      "\n",
      "* **새로운 리스트를 반환합니다.** 원본 리스트는 변경되지 않습니다.\n",
      "* **`key` 인자와 `reverse` 인자를 `list.sort()`와 동일하게 사용합니다.**\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬\n",
      "sorted_list = sorted(my_list)\n",
      "print(f\"오름차순 정렬 (sorted 함수): {sorted_list}\")  # 출력: 오름차순 정렬 (sorted 함수): [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "print(f\"원본 리스트: {my_list}\")  # 출력: 원본 리스트: [3, 1, 4, 1, 5, 9, 2, 6] (변경되지 않음)\n",
      "\n",
      "# 내림차순 정렬\n",
      "sorted_list = sorted(my_list, reverse=True)\n",
      "print(f\"내림차순 정렬 (sorted 함수): {sorted_list}\") # 출력: 내림차순 정렬 (sorted 함수): [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "어떤 방법을 사용할지는 상황에 따라 선택하면 됩니다.  원본 리스트를 변경하고 싶지 않다면 `sorted()` 함수를, 원본 리스트를 직접 변경하고 메모리를 절약하고 싶다면 `list.sort()` 메서드를 사용하는 것이 효율적입니다.  `key` 인자를 활용하여 다양한 정렬 기준을 적용할 수 있다는 점을 기억하세요.\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\"name\": \"네이버\", \"year\": \"1999\", \"location\": \"경기도 성남\"}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "예제 3: 번역 체인\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
