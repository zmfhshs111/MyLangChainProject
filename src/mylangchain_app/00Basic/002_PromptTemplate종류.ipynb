{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_n\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 인터넷의 방대한 텍스트에서 단어와 문장의 등장 패턴을 통계적으로 학습합니다.  \\n'\n",
      " '학습 과정에서 모델은 주어진 앞단어들을 바탕으로 다음에 올 토큰의 확률을 예측하며, 이를 반복해 문장을 생성합니다.  \\n'\n",
      " '인간의 피드백 강화학습(RLHF)으로 가치를 조정해 유용하고 안전한 응답을 만들어냅니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. \\\n",
    "     Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(llm)\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨팅에 대하여 설명해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? \\\n",
    "        {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season()  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "1. 대기청정도 높아지는 ‘고기압 안정권’  \n",
      "   가을이 되면 북서쪽에서 내려온 차고 건조한 고기압이 한반도를 장기간 지배한다. 위에서 내려오는 공기가 점차 가열되면서 대기가 안정층을 이루고, 수증기·미세먼지가 위로 올라가지 못해 시야가 맑아진다. 덕분에 하늘이 높고 푸르게 보이는 ‘가을 고기압’ 현상이 나타난다.\n",
      "\n",
      "2. 단풍(엽색변화)  \n",
      "   일교차가 크고 햇빛이 강한 10월 무렵, 나뭇잎의 엽록소가 파괴되면서 기존에 숨겨졌던 카로티노이드·안토시아닌 등의 색소가 드러난다. 고도·위도에 따라 산 정상부턴데 단풍이 먼저 시작되며, 2 주 정도면 산 전체가 붉고 노랗게 물든다.\n",
      "\n",
      "3. 산악풍속 차가운 ‘결로·안개’  \n",
      "   밤 사방이 방사냉각으로 냉각된 산록이나 계곡은 주변 공기보다 기온이 낮아지면서, 공기 중 수증기가 응결해 백색의 박무(산안개)를 형성한다. 특히 계곡 바닥에 깔리는 ‘계곡안개’는 이른 아침에 차가운 공기가 낮은 곳에 고여 있을 때 자주 관측된다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: 현재 환율 1달러 = 1,377.98원은 **역대 최고 수준**에 근접한 수치입니다. 단순 숫자를 넘어 한국 경제·금융 시스템에 복합적 파급효과를 낳고 있어, 아래 4가지 축으로 정리해 드립니다.\n",
      "\n",
      "1. 도달 배경 (Why so high?)  \n",
      "   - 미국발 고금리·강달러: 연준 기준금리 5.25~5.50 % vs 한국 3.50 % → 역(逆)금리 차 1.75 %p.  \n",
      "   - 안전자산 선호: 연준 ‘higher for longer’ +美 디폴트·부채리스크 논란 → 달러수요↑.  \n",
      "   - 한국 경상수지 적자 전환: 에너지·원자재 고물가 + 수출 둔화로 2022년 4분기 이후 5분기 연속 누적 적자(또는 흑자 축소).  \n",
      "   - 중국·동남아 수출 둔화: 한국 수출의 50 %가량이 이 지역 직간접 의존.  \n",
      "   - 외국인 자금 이탈: 2023년 4월~5월 韓 주식·채권시장에서 80억 달러 이상 순유출.  \n",
      "   - ‘원化’ 유동성↑: 올들어 韓 기업 해외차입 규모(달러 표시) 2022년 대비 20 % 증가 → 달러 수요 늘고 원화 공급↑.\n",
      "\n",
      "2. 거시경제·시장 임팩트  \n",
      "   물가·가계  \n",
      "   - 수입물가 상승률 1 % → 소비자물가 상승률 0.15~0.2 %(BOK 추정).  \n",
      "   - 1,400원 돌파 시 연간 물가 0.4 %p 추가 상승 → 목표치(2 %) 상회.  \n",
      "   기업  \n",
      "   - 수입 의존업종(석유·화학, 식품, 항공유) 원가↑, 내수·건설 자재비↑.  \n",
      "   - 수출기업(반도체·조선·자동차) 환율 플러스지만, 수입 원자재 비중이 높아 순이익 개선은 제한적.  \n",
      "   - 2022년 연결결기준 韓 상장사 40 %가 재무상황표상 ‘외화차입’ 보유 → 환차손 위험.  \n",
      "   금융  \n",
      "   - 은행·증권社 외화PF(프로젝트파이낸스) 부실 우려.  \n",
      "   - 외환변동성 ↑ → CDS 프리미엄 70bp(5월 기준)로 1년 새 두 배.  \n",
      "   - 가계부채 1,870조 원 중 변동금리 비중 55 % → 금리·환율 이중부담.\n",
      "\n",
      "3. 정책 대응 현황  \n",
      "   - 한국은행: 1) 美 통화스와프(조기) 재활용, 2) 외화유동성 공급(CDC) 360억 달러, 3) ‘외화안정화 브리지’ 50억 달러.  \n",
      "   - 재정·산업부: 수입 물류비·에너지비 지원(올해 5조 원), 수출보험·보증 11조 원.  \n",
      "   - 금융당국: 외화·원화동시차입 규제 완화(LCR·NSFR), 외국환은행 한도 확대.  \n",
      "   - 시장개입(Verbal & Actual): 5월 美 재무부 방한 직전 2.7조 원 규모 달러 매도(외환평형기금) → ‘넘버’ 1,400원 무력화 의지 표명.\n",
      "\n",
      "4. 향후 전개 시나리오 (향후 6~12개월)  \n",
      "   ① ‘연준 금리 동결→물가 둔화→달러 약세’ 시(확률 45 %)  \n",
      "      – 달러인덱스 100→95, 원/달러 1,300원 후반.  \n",
      "   ② ‘연준 추가 금리 인상 or 글로벌 경기 침체’ 시(확률 30 %)  \n",
      "      – 1달러 1,450원 돌파 가능성.  \n",
      "   ③ ‘현 수준 유지’ 시(확률 25 %)\n",
      "\n",
      "핵심 모니터링 지표  \n",
      "   - 미국 CPI·PCE(물가), 물가 기대치(5Y5Y breakeven), 연준 dot plot  \n",
      "   - 한국 경상수지(6월까지 누적), 관광·운송수지(‘에어분수’ 회복)  \n",
      "   - 韓·美 금리차(10년물 국채 스프레드)  \n",
      "   - 외국인 주식·채권 순매수(+), 외화 예수금·외화대출 변화  \n",
      "   - 중국 PMI, EU PMI(한국 수출의 25 % 수요)\n",
      "\n",
      "투자·운용 관점  \n",
      "   - **헤지**: 수입 의존 기업·가계는 달러 선물환(6개월물) 1,350원대에 70~80 % 물량 롤오버.  \n",
      "   - **수출기업**: 달러 매도헤지(put spread) 1,300원 스트라이크·1,250원 스트라이크 조합으로 비용 절감.  \n",
      "   - **자산배분**: 원화 약세 지속 시 원자재 ETF(금, 구리), 내수 물가 연동 우선주(통신·소매) 비중 확대.  \n",
      "   - **국내 채권**: 역외물 5년물 IRS 3.8 % 수준, 금리 상단 구간 → 중단기 국채 선호.  \n",
      "   - **주식**: 원화강세(1,300원 이하) 시 반도체·배터리·화장품 업종 PER 디스카운트 해소 → 선행매수.\n",
      "\n",
      "종합  \n",
      "   “기준금리 역차 + 경상수지 악화 + 글로벌 안전자산 선호”가 맞물리며 1,400원에 근접한 고환율이 지속되고 있습니다. 연준이 금리 인상을 멈추거나 실질 금리가 둔화될 때까지 1,300원 중·후반에서 등락할 가능성이 크며, 1,400원 돌파 시 한국은행의 추가 외환시장 개입(물적·언어)과 재정·금융지원이 병행될 것으로 예상됩니다. 기업과 가계는 환율 리스크를 사전에 분산·헤지하고, 글로벌 경기·물가 지표를 면밀히 체크하면서 단계적 대응 전략을 수립하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
