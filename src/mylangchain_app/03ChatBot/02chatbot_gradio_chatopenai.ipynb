{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pyLTgWwvQhV"
   },
   "source": [
    "그라디오 챗봇와 랭체인 LLM 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29624,
     "status": "ok",
     "timestamp": 1739071493071,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "mho6mQWYvUle",
    "outputId": "05496f39-0f87-447e-d46a-0edbf9566171"
   },
   "outputs": [],
   "source": [
    "# 그라디오 라이브러리를 설치합니다.\n",
    "#poetry add gradio \n",
    "# 랭체인 라이브러리를 설치합니다.\n",
    "#poetry add langchain \n",
    "# 랭체인 OpenAI 연동 라이브러리를 설치합니다.\n",
    "#poetry add langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain의 ChatOpenAI가 환경 변수를 자동으로 로드하는 방식\n",
    "* load_dotenv()를 실행하면 .env 파일에 있는 환경 변수가 시스템 환경 변수로 등록됨\n",
    "* LangChain의 ChatOpenAI는 api_key=None일 때 os.getenv(\"OPENAI_API_KEY\")를 자동으로 불러옴\n",
    "* 따라서 api_key를 명시적으로 설정하지 않아도 API 키가 자동으로 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739073587961,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "1eHQ5ThX3KHP"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4273,
     "status": "ok",
     "timestamp": 1739073595715,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "3_Wj7jaE4giS",
    "outputId": "b9e33cb5-b7d6-4080-89eb-7722641b7f50"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "#llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"파이썬이란?\"}])\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API 키를 명시적으로 설정하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 명시적으로 API 키 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY)  \n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"파이썬이란?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "executionInfo": {
     "elapsed": 120391,
     "status": "ok",
     "timestamp": 1739073719232,
     "user": {
      "displayName": "Myung Sook Baek",
      "userId": "06392624545902733911"
     },
     "user_tz": -540
    },
    "id": "wRX0aUZk7Zul",
    "outputId": "5eba57b6-5fbf-4597-de9a-d473e943d423"
   },
   "outputs": [],
   "source": [
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr\n",
    "# LangChain 의 ChatOpenAI 를 불러옵니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 인스턴스 생성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def chat_respond(message, chat_history):  \n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": message}])\n",
    "    bot_message = response.content\n",
    "    \n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chat_history  \n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:  \n",
    "    chatbot = gr.Chatbot(label=\"채팅창\", type=\"messages\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(chat_respond, [msg, chatbot], [msg, chatbot])  \n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  \n",
    "\n",
    "# 인터페이스를 실행합니다. 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며, '초기화' 버튼을 통해 채팅 기록을 초기화 할 수 있습니다.\n",
    "demo.launch(debug=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObKSkPPvS7YmfW96AW/9bs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
