{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1F5lTDp5UPf0",
   "metadata": {
    "id": "1F5lTDp5UPf0"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6"
   },
   "outputs": [],
   "source": [
    "# poetry add pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a416db3",
   "metadata": {},
   "source": [
    "#### PyPDFLoader 간단한 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd95056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 경로 설정\n",
    "pdf_filepath = '../data/tutorial-korean.pdf'\n",
    "\n",
    "# 파일 존재 여부 확인 (파일이 없으면 오류 발생)\n",
    "if not os.path.exists(pdf_filepath):\n",
    "    raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {pdf_filepath}\")\n",
    "\n",
    "try:\n",
    "    # 1. PDF 파일 로드\n",
    "    loader = PyPDFLoader(pdf_filepath)  # PDF 파일을 로드할 객체 생성\n",
    "    docs = loader.load()  # 문서를 전체 로드\n",
    "\n",
    "    # 총 문서 개수 출력 [Document,Document]\n",
    "    print(f\"총 {len(docs)}개의 문서가 로드 되었습니다.\")\n",
    "\n",
    "    #  첫 번째 문서의 메타데이터 출력\n",
    "    print(\"첫 번째 문서 메타데이터:\")\n",
    "    print(json.dumps(docs[0].metadata, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # 특정 인덱스(10번째) 문서의 내용 확인 (존재할 경우)\n",
    "    if len(docs) > 10:\n",
    "        print(\"\\n10번째 문서 내용:\", type(docs[10]))\n",
    "        print(docs[10])  # 10번째 문서 출력\n",
    "\n",
    "    #  2. 텍스트 분할 (200자 단위, 중첩 없음)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "    split_docs = loader.load_and_split(text_splitter=text_splitter)  # 분할된 문서 로드\n",
    "\n",
    "    # 분할된 문서 개수 출력\n",
    "    print(f\"\\n분할된 문서의 개수: {len(split_docs)} 타입: {type(split_docs)}\")\n",
    "\n",
    "    # 10번째 분할된 문서 내용 출력 (존재할 경우)\n",
    "    if len(split_docs) > 10:\n",
    "        print(\"\\n10번째 분할된 문서:\")\n",
    "        print(split_docs[10])\n",
    "\n",
    "    # 3. Lazy Load 방식으로 문서 로드\n",
    "    print(\"\\nLazy Load 방식으로 문서 로드:\")\n",
    "    for i, doc in enumerate(loader.lazy_load()):\n",
    "        if i < 5:  # 너무 많은 출력 방지 (예제: 처음 5개만 출력)\n",
    "            print(json.dumps(doc.metadata, indent=2, ensure_ascii=False))\n",
    "\n",
    "except Exception as e:\n",
    "    # 오류 발생 시 메시지 출력\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c50bf6",
   "metadata": {},
   "source": [
    "#### OllamaEmbeddings\n",
    "* bge-m3:latest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "print(\"==> 1. 문서 로딩 → PDF 읽기...\")\n",
    "loader = PyPDFLoader('../data/tutorial-korean.pdf')\n",
    "documents = loader.load()\n",
    "print(f\"  총 {len(documents)}페이지 로드 완료\")\n",
    "\n",
    "print(\"==> 2. 문서 분할 → 작은 청크로 나누기\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # 청크 크기 (한국어 최적화)\n",
    "    chunk_overlap=200,      # 중복 부분 (맥락 보존)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"] # 자연스러운 분할을 위한 구분자\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"  {len(chunks)}개 청크 생성 완료\")\n",
    "print(f\"  평균 청크 길이: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f}자\")\n",
    "\n",
    "print(\"==> 3. 벡터화 → 임베딩으로 변환\")\n",
    "# embeddings = OpenAIEmbeddings(\n",
    "#     model=\"text-embedding-3-small\",\n",
    "#     dimensions=1536\n",
    "# )\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "\n",
    "print(\"==> 4. 저장 → FAISS 벡터스토어에 저장\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(f\" FAISS 벡터스토어 생성 완료 ({len(chunks)}개 벡터)\")\n",
    "vectorstore.save_local(\"faiss_db\")\n",
    "\n",
    "print(\"===> 5. 검색 → 질문과 유사한 문서 찾기\")\n",
    "# VectorStoreRetriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}  # 상위 6개 관련 문서 검색\n",
    ")\n",
    "print(\" Retriever 설정 완료\")\n",
    "\n",
    "print(\"===> 6. 생성 → LLM으로 답변 생성\")\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=1500\n",
    "# )\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 한국어 최적화 프롬프트\n",
    "prompt_template = \"\"\"\n",
    "당신은 BlueJ 프로그래밍 환경 전문가입니다. \n",
    "아래 문서 내용을 바탕으로 정확하고 친절한 답변을 제공해주세요.\n",
    "\n",
    "문서 내용:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 규칙:\n",
    "1. 문서 내용만을 근거로 답변하세요\n",
    "2. 단계별 설명이 필요하면 순서대로 작성하세요  \n",
    "3. 구체적인 메뉴명, 버튼명을 포함하세요\n",
    "4. 문서에 없는 정보는 \"문서에서 찾을 수 없습니다\"라고 하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "print(\" 프롬프트 설정 완료\")\n",
    "\n",
    "# ===================================\n",
    "# 7. QA 체인 생성 Retriever + Prompt +LLM을 체인으로 연결\n",
    "# ===================================\n",
    "print(\"\\n ===> 7.  QA 체인 생성...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "print(\"  RAG 파이프라인 구축 완료!\")\n",
    "\n",
    "question = \"BlueJ에서 객체를 생성하는 방법은 무엇인가요?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884754ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================\n",
    "# 8. 테스트 질문들\n",
    "# ===================================\n",
    "test_questions = [\n",
    "    \"BlueJ에서 객체를 생성하는 방법은 무엇인가요?\",\n",
    "    \"컴파일 오류가 발생했을 때 어떻게 확인할 수 있나요?\", \n",
    "    \"디버깅을 위해 중단점을 설정하는 방법을 알려주세요\",\n",
    "    \"코드패드는 무엇이고 어떻게 사용하나요?\",\n",
    "    \"애플릿을 만들고 실행하는 방법을 설명해주세요\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" RAG 시스템 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===================================\n",
    "# 9. 질문 및 답변 실행\n",
    "# ===================================\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n【테스트 {i}/5】\")\n",
    "    print(f\" 질문: {question}\")\n",
    "    print(\" 답변 생성 중...\")\n",
    "    \n",
    "    # RAG 실행\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    print(f\"\\n 답변:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(answer)\n",
    "    \n",
    "    # 참조 문서 정보\n",
    "    print(f\"\\n 참조 문서:\")\n",
    "    for j, doc in enumerate(source_docs[:3], 1):\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        preview = doc.page_content[:80].replace('\\n', ' ')\n",
    "        print(f\"   {j}. 페이지 {page}: {preview}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd25a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d910ef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
