{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83efc973-52a7-4dd7-a1fd-f0e24729c061",
   "metadata": {
    "id": "83efc973-52a7-4dd7-a1fd-f0e24729c061"
   },
   "source": [
    "#### RAG (Retrieval-Augmented Generation)\n",
    "- 모델의 학습 데이터에 포함되지 않은 데이터를 사용 (환각 방지)\n",
    "- **외부 데이터**를 검색(retrieval)한 후, 생성(generation) 단계에서 LLM에 전달\n",
    "- 모델은 주어진 컨텍스트나 질문에 더 적합하고 풍부한 정보를 반영한 답변을 생성\n",
    "- 논문: https://arxiv.org/abs/2005.11401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DEJbhYzzUZ-K",
   "metadata": {
    "id": "DEJbhYzzUZ-K"
   },
   "source": [
    "## 0. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1F5lTDp5UPf0",
   "metadata": {
    "id": "1F5lTDp5UPf0"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6"
   },
   "outputs": [],
   "source": [
    "#%pip install -q langchain langchain-openai langchain_community tiktoken faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NU1VnNaZN2-d",
   "metadata": {
    "id": "NU1VnNaZN2-d"
   },
   "source": [
    "### 1. RAG 파이프라인 개요\n",
    "* Load Data - Text Split - Indexing - Retrieval - Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PufJBHgTaA-L",
   "metadata": {
    "id": "PufJBHgTaA-L"
   },
   "source": [
    "##### Step 1: Load Data\n",
    "* 1. WebBaseLoader를 사용하여 웹 페이지 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa52de-4a17-4c6a-a890-7ef82ed22ffc",
   "metadata": {
    "id": "6f5e3a62-f0a8-4d03-b983-d33de460d229"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 웹 요청을 위한 USER_AGENT 환경 변수 설정 (필요한 경우)\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "\n",
    "# 환경 변수 확인\n",
    "print(f\"현재 설정된 USER_AGENT: {os.environ.get('USER_AGENT')}\")\n",
    "\n",
    "# 웹페이지 URL 지정  https://ko.wikipedia.org/wiki/축구_경기_규칙\n",
    "url = 'https://ko.wikipedia.org/wiki/%EC%B6%95%EA%B5%AC_%EA%B2%BD%EA%B8%B0_%EA%B7%9C%EC%B9%99'\n",
    "\n",
    "# WebBaseLoader 초기화 및 데이터 로드\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서 확인\n",
    "print(type(docs), len(docs))\n",
    "print(docs)\n",
    "print(type(docs[0]))  # <class 'langchain_core.documents.Document'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32e89f-e4f0-48c6-ac62-7d752ea185bf",
   "metadata": {
    "id": "6f5e3a62-f0a8-4d03-b983-d33de460d229"
   },
   "outputs": [],
   "source": [
    "print(len(docs[0].page_content))\n",
    "print(docs[0].page_content[5000:5500])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vzBeboLlaIuy",
   "metadata": {
    "id": "vzBeboLlaIuy"
   },
   "source": [
    "##### Step 2: 문서 분할(Splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c79cca",
   "metadata": {},
   "source": [
    "* WebBaseLoader를 사용하여 웹 페이지에서 가져온 데이터를 RAG 시스템에서 효율적으로 활용하기 위해 작은 청크(chunks)로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f653d-dcfb-432b-b090-40476aa4c29c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c64f653d-dcfb-432b-b090-40476aa4c29c",
    "outputId": "3ed2f01a-db0a-4256-e4bb-ff998078ba18"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "\n",
    "# 문서 분할\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 분할된 문서 확인\n",
    "print(type(splits), len(splits))  # 총 몇 개의 청크가 생성되었는지 확인\n",
    "print(type(splits[0]))\n",
    "print(splits[0].page_content[:80])  # 첫 번째 청크의 일부 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49bd43-5adb-4862-8134-78645ad068e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "bc49bd43-5adb-4862-8134-78645ad068e7",
    "outputId": "71cb4855-b814-4c01-8439-3ffacf576768"
   },
   "outputs": [],
   "source": [
    "# 열번째 청크의 내용 출력\n",
    "print(splits[10].page_content[:20])\n",
    "# 열번째 청크의 메타데이터 출력\n",
    "print(splits[10].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-PLZMd4baaLc",
   "metadata": {
    "id": "-PLZMd4baaLc"
   },
   "source": [
    "##### Step 3: 벡터 DB에 저장 및 검색\n",
    "* Indexing (Texts -> Embedding -> Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b104013-e54c-409f-864e-7e6655a67743",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b104013-e54c-409f-864e-7e6655a67743",
    "outputId": "bd089fd3-981f-41d8-9fe3-f896042318b4"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS  # 벡터 저장소 라이브러리\n",
    "from langchain_openai import OpenAIEmbeddings # OpenAI의 임베딩(Embedding) 모델\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "print(embedding)\n",
    "\n",
    "# 1. FAISS 벡터 저장소 생성\n",
    "# - documents: 텍스트 데이터를 벡터화 하여 저장할 문서 리스트\n",
    "# - embedding: 문서를 벡터로 변환하는 OpenAI Embeddings 모델 사용\n",
    "#embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
    "\n",
    "# 2. 유사 문서 검색 (Similarity Search)\n",
    "# - \"경기장 표시에 대해서 설명해주세요.\"라는 쿼리에 대해,\n",
    "# - FAISS 벡터 저장소에서 가장 유사한 문서를 검색함.\n",
    "docs = vectorstore.similarity_search(\"경기장 표시에 대해서 설명해주세요.\")\n",
    "\n",
    "# 3. 검색된 문서의 타입과 개수 출력\n",
    "print(type(docs), len(docs))\n",
    "# 4. 검색된 첫 번째 문서 내용 출력\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mYrHWwsnajPY",
   "metadata": {
    "id": "mYrHWwsnajPY"
   },
   "source": [
    "##### Step 4: RAG Pipeline을 이용한 질의응답 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99275d3-abb2-4bc3-b783-2afc37d4b666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "e99275d3-abb2-4bc3-b783-2afc37d4b666",
    "outputId": "39a07730-20ee-43b7-df52-e02a9c70b598"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  # OpenAI LLM(대화형 언어 모델)\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate  # 프롬프트 템플릿\n",
    "from langchain_core.runnables import RunnablePassthrough  # 입력을 그대로 전달하는 유틸리티\n",
    "from langchain_core.output_parsers import StrOutputParser  # LLM 응답을 문자열로 변환하는 파서\n",
    "from pprint import pprint\n",
    "\n",
    "# 검색 개수 제한 설정\n",
    "# - 벡터 저장소(vectorstore)에서 관련성이 높은 문서 최대 3개를 검색하도록 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  \n",
    "\n",
    "def format_docs(docs):\n",
    "    summaries = [f\"출처: {doc.metadata.get('source', '알 수 없음')}\\n\" \\\n",
    "                 + doc.page_content[:300] + \"...\" for doc in docs]\n",
    "    return \"\\n\\n\".join(summaries)    \n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "# - 모델이 주어진 `context`(검색된 문서)만을 참고하여 질문에 답변하도록 유도하는 프롬프트 템플릿\n",
    "# - {context}: 검색된 문서 요약이 삽입될 자리\n",
    "# - {question}: 사용자의 질문이 삽입될 자리\n",
    "template = '''당신은 제공된 컨텍스트를 기반으로 질문에 답하는 AI 어시스턴트입니다. \n",
    "반드시 컨텍스트 내 정보를 활용하여 정확하고 신뢰할 수 있는 답변을 제공하세요.\n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변]\n",
    "'''\n",
    "\n",
    "# - 위에서 정의한 템플릿을 사용하여 LangChain의 프롬프트 객체 생성\n",
    "prompt = ChatPromptTemplate.from_template(template)  \n",
    "\n",
    "# LLM 모델 설정\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",\n",
    "#     model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)\n",
    "\n",
    "\n",
    "# RAG 체인 설정\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}  \n",
    "    # - `retriever`를 통해 검색된 문서를 `format_docs()` 함수로 가공하여 `context`로 전달\n",
    "    # - `question`은 변형 없이 그대로 전달\n",
    "    | prompt  # - 위에서 정의한 `ChatPromptTemplate`을 적용\n",
    "    | llm   # - OpenAI GPT-3.5 모델을 사용해 응답 생성\n",
    "    | StrOutputParser()  # - 모델의 응답을 문자열로 변환\n",
    ")\n",
    "\n",
    "# 실행 (사용자 질문을 입력으로 받아 RAG 체인 실행)\n",
    "# - \"경기장 표시에 대해서 설명해주세요.\"라는 질문을 LLM에 전달하여 답변을 생성\n",
    "response = rag_chain.invoke(\"경기장 표시에 대해서 설명해주세요.\")  \n",
    "\n",
    "# 최종 응답 출력\n",
    "print(f\" 모델 응답:\\n\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b559119",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"선수의 장비에 대하여 설명해 주세요.\"\n",
    "\n",
    "response = rag_chain.invoke(query)  \n",
    "\n",
    "# 최종 응답 출력\n",
    "print(f\" 모델 응답:\\n\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c14be",
   "metadata": {},
   "source": [
    "### Level2 - 개선된 Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59746dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 RAG 파이프라인 - 축구 규칙 질의응답 시스템\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "# 환경 설정\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "\n",
    "print(\"=== 개선된 RAG 파이프라인 시작 ===\\n\")\n",
    "\n",
    "# Step 1: 웹 데이터 로드\n",
    "print(\" Step 1: 웹페이지 데이터 로딩...\")\n",
    "url = 'https://ko.wikipedia.org/wiki/%EC%B6%95%EA%B5%AC_%EA%B2%BD%EA%B8%B0_%EA%B7%9C%EC%B9%99'\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "print(f\" 로드된 문서 수: {len(docs)}\")\n",
    "print(f\" 전체 텍스트 길이: {len(docs[0].page_content):,} 문자\\n\")\n",
    "\n",
    "# Step 2: 개선된 문서 분할 (더 작은 청크, 더 많은 overlap)\n",
    "print(\" Step 2: 문서 분할 (개선된 설정)...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 기존 3000 → 1000으로 감소 (더 세밀한 검색)\n",
    "    chunk_overlap=200,  # overlap 유지\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]  # 분할 우선순위 명시\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\" 분할된 청크 수: {len(splits)} (기존 대비 증가)\")\n",
    "print(f\" 첫 번째 청크 예시: {splits[0].page_content[:100]}...\\n\")\n",
    "\n",
    "# Step 3: 개선된 벡터 저장소 생성 및 검색 설정\n",
    "print(\" Step 3: 벡터 저장소 생성 및 검색 설정...\")\n",
    "#embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embedding  # 최신 임베딩 모델 사용\n",
    ")\n",
    "\n",
    "# 개선된 검색 설정: 더 많은 문서 검색\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}  # 기존 3 → 6으로 증가\n",
    ")\n",
    "print(\" 벡터 저장소 및 검색기 설정 완료\\n\")\n",
    "\n",
    "# Step 4: 개선된 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 LLM이 이해하기 쉬운 형태로 포맷팅\"\"\"\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        # 메타데이터에서 출처 정보 추출\n",
    "        source = doc.metadata.get('source', '알 수 없음')\n",
    "        \n",
    "        # 문서 내용 정리 (불필요한 공백 제거)\n",
    "        content = doc.page_content.strip()\n",
    "        \n",
    "        # 각 문서를 번호와 함께 명확히 구분\n",
    "        formatted_doc = f\"[문서 {i}]\\n출처: {source}\\n내용: {content}\\n\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    \n",
    "    return \"\\n\" + \"=\"*50 + \"\\n\".join(formatted_docs) + \"=\"*50 + \"\\n\"\n",
    "\n",
    "# Step 5: 개선된 프롬프트 템플릿\n",
    "print(\" Step 4: 개선된 프롬프트 설정...\")\n",
    "\n",
    "template = '''당신은 축구 규칙 전문가입니다. 아래 제공된 컨텍스트를 바탕으로 사용자의 질문에 정확하고 상세하게 답변해주세요.\n",
    "\n",
    "**답변 지침:**\n",
    "1. 제공된 컨텍스트의 정보만을 사용하여 답변하세요\n",
    "2. 구체적인 수치, 규칙, 조건들을 포함하여 상세히 설명하세요\n",
    "3. 관련된 여러 규칙이 있다면 체계적으로 정리해주세요\n",
    "4. 컨텍스트에 없는 정보는 추측하지 마세요\n",
    "\n",
    "**컨텍스트:**\n",
    "{context}\n",
    "\n",
    "**질문:** {question}\n",
    "\n",
    "**답변:**\n",
    "위 컨텍스트를 바탕으로 질문에 대해 상세히 답변드리겠습니다.\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Step 6: LLM 설정\n",
    "print(\" Step 5: LLM 모델 설정...\")\n",
    "# model = ChatOpenAI(\n",
    "#     model='gpt-4o-mini',  # 더 강력한 모델 사용\n",
    "#     temperature=0.1,  # 약간의 창의성 허용하되 일관성 유지\n",
    "#     max_tokens=1500   # 더 길고 상세한 답변 허용\n",
    "# )\n",
    "\n",
    "model = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "# Step 7: RAG 체인 구성\n",
    "print(\" Step 6: RAG 체인 구성...\")\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\" RAG 파이프라인 설정 완료!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"선수의 장비에 대하여 설명해 주세요.\"\n",
    "\n",
    "response = rag_chain.invoke(query)  \n",
    "\n",
    "# 최종 응답 출력\n",
    "print(f\" 모델 응답:\\n\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: 테스트 실행\n",
    "def ask_question(question):\n",
    "    \"\"\"질문을 받아 RAG 시스템으로 답변 생성\"\"\"\n",
    "    print(f\" 질문: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 관련 문서 먼저 확인\n",
    "    docs = retriever.invoke(question)\n",
    "    print(f\" 검색된 관련 문서 수: {len(docs)}\")\n",
    "    \n",
    "    # RAG 체인 실행\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    print(\" 답변:\")\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# 테스트 질문들\n",
    "if __name__ == \"__main__\":\n",
    "    test_questions = [\n",
    "        \"경기장 표시에 대해서 설명해주세요.\",\n",
    "        \"페널티 에어리어의 크기와 규격은 어떻게 되나요?\",\n",
    "        \"오프사이드 규칙에 대해 자세히 설명해주세요.\",\n",
    "        \"축구공의 규격과 요구사항은 무엇인가요?\",\n",
    "        \"골키퍼가 할 수 없는 행동들은 무엇인가요?\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        ask_question(question)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
