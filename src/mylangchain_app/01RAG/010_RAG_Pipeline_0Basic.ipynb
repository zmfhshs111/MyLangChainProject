{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "DEJbhYzzUZ-K",
   "metadata": {
    "id": "DEJbhYzzUZ-K"
   },
   "source": [
    "## 0. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1F5lTDp5UPf0",
   "metadata": {
    "id": "1F5lTDp5UPf0"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain_community faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59379f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"bge-m3:latest\"\n",
    "EMBEDDING_MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90e845",
   "metadata": {},
   "source": [
    "#### RAG 파이프 라인\n",
    "* Load Data - Text Split - Indexing - Retrieval - Generation\n",
    "* OllamaEmbeddings 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. Load Data\n",
    "loader = TextLoader(\"../data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(type(documents), len(documents)) #[Documentm, Document]\n",
    "print(type(documents[0]))\n",
    "#print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2️. Text Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "print(len(split_docs), type(split_docs))\n",
    "print(split_docs[0])\n",
    "print('두번째 Document ====================')\n",
    "print(split_docs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3️. Indexing (벡터 저장)\n",
    "embeddings_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_docs, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "#vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "\n",
    "# 로컬 파일로 저장\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969466b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4️. Retrieval (유사 문서 검색) k: 질의와 가장 유사한 문서(청크) 6개를 찾아 반환하기\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "print(type(retriever))\n",
    "# **질문(쿼리)**에 대해 유사한 문서를 검색하는 역할\n",
    "retrieved_docs = retriever.invoke(\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\")\n",
    "print(type(retrieved_docs), len(retrieved_docs))\n",
    "print(type(retrieved_docs[0]))\n",
    "print(retrieved_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b621c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5️. Generation (LLM 응답 생성)\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_context = llm.invoke(f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요? 관련 정보: {context}\")\n",
    "print('context 적용한 결과')\n",
    "pprint(response_context.content)\n",
    "\n",
    "response = llm.invoke(f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\")\n",
    "print('context 적용하지 않은 결과')\n",
    "pprint(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d2850",
   "metadata": {},
   "source": [
    "### 개선한 Source - version1\n",
    "* Retriever 검색방법 개선\n",
    "    * search_type=\"mmr\",  # 최대 다양성 검색\n",
    "    * search_kwargs={\"k\": 6, \"fetch_k\": 10}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b03769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. 데이터 로드 (기존과 동일)\n",
    "loader = TextLoader(\"../data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. 텍스트 분할 개선\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 크기 증가\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 자연스러운 분할을 위한 구분자\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "# 3. 인덱싱 (벡터 저장)\n",
    "embeddings_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_docs, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "#vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "# 4. 검색 개선\n",
    "\"\"\"\n",
    "    최대 다양성 검색(Maximum Marginal Relevance, MMR)\n",
    "    MMR은 유사도가 높은 문서를 찾는 것을 넘어, 유사도와 다양성이라는 두 가지 기준을 모두 고려함\n",
    "    - search_type=\"mmr\": 검색 방식을 MMR로 지정합니다.\n",
    "    - fetch_k: 일차적으로 질의와 유사한 문서 10개를 벡터 저장소에서 가져옵니다.\n",
    "    - k: fetch_k로 가져온 10개의 문서 중에서 최종적으로 6개를 선택합니다. 6개를 선택할 때, MMR 알고리즘은 다음 두 가지를 고려함\n",
    "        : 질의와의 유사도가 높고, 이미 선택된 다른 문서들과의 유사도가 낮은 (즉, 내용이 다양한) 문서\n",
    "    * MMR의 작동 원리:\n",
    "    - 질의와 가장 유사한 fetch_k개(10개)의 문서를 예비 후보군으로 가져옵니다.\n",
    "    - 이 후보군 중에서 질의와 가장 유사한 문서 하나를 첫 번째 결과로 선택합니다.\n",
    "    - 남은 후보군 중에서 질의와의 유사도는 높으면서 (관련성), \n",
    "      이미 선택된 문서들과의 유사도는 낮은 (다양성) 문서를 찾아 다음 결과로 추가함\n",
    "    - 이 과정을 k개(6개)의 문서가 모두 선택될 때까지 반복합니다.        \n",
    "\"\"\"\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # 최대 다양성 검색\n",
    "    search_kwargs={\"k\": 6, \"fetch_k\": 10}  # 더 많은 결과 검색\n",
    ")\n",
    "\n",
    "# 5. 프롬프트 엔지니어링\n",
    "def generate_prompt(query, context):\n",
    "    return f\"\"\"다음은 소득세법 비과세소득 관련 조항입니다. 문맥을 고려하여 질문에 답변하세요.\n",
    "\n",
    "[관련 조항]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[답변 요구사항]\n",
    "- 비과세소득 유형을 계층적으로 구분하여 설명\n",
    "- 각 항목별 구체적인 조건 명시\n",
    "- 법조문의 항, 호, 목 번호를 포함\n",
    "- 500자 이내로 간결하게 요약\"\"\"\n",
    "\n",
    "# 검색 및 응답 생성\n",
    "query = \"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)  # 창의성 낮춤\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "response = llm.invoke(generate_prompt(query, context))\n",
    "\n",
    "print('개선된 결과:')\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737c46e",
   "metadata": {},
   "source": [
    "### 개선한 Source - version2\n",
    "* Prompt 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ee0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. Load Data\n",
    "loader = TextLoader(\"../data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"=== 원본 문서 길이 ===\")\n",
    "print(f\"전체 문서 길이: {len(documents[0].page_content)} 글자\")\n",
    "\n",
    "# 2. Text Split 개선\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  \n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # 법령 구조에 맞는 분리자\n",
    ")\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"분할된 문서 수: {len(split_docs)}개\")\n",
    "print(\"=== 분할 예시 ===\")\n",
    "for i, doc in enumerate(split_docs[:3]):\n",
    "    print(f\"Chunk {i+1} ({len(doc.page_content)}글자): {doc.page_content[:100]}...\")\n",
    "\n",
    "# 3. Indexing\n",
    "embeddings_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_docs, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "#vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "# 4. Retrieval 개선\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 6}  \n",
    ")\n",
    "\n",
    "query = \"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n=== 검색된 문서 ({len(retrieved_docs)}개) ===\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:200]}...\")\n",
    "    print(\"---\")\n",
    "\n",
    "# 5. Generation - 개선된 프롬프트\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0\n",
    ")\n",
    "context = \"\\n\\n\".join([f\"[문서 {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "\n",
    "# 개선된 프롬프트 - 더 구체적인 지시사항\n",
    "improved_prompt = f\"\"\"\n",
    "당신은 세무 전문가입니다. 아래 소득세법 제12조 조항을 바탕으로 질문에 답변해주세요.\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "법령 조항:\n",
    "{context}\n",
    "\n",
    "다음 형식으로 답변해주세요:\n",
    "1. 비과세소득의 정의\n",
    "2. 주요 비과세소득 항목들을 다음과 같이 분류:\n",
    "   - 사업소득 관련\n",
    "   - 근로소득/퇴직소득 관련  \n",
    "   - 연금소득 관련\n",
    "   - 기타소득 관련\n",
    "3. 각 항목별 구체적인 조건이나 한도액 명시\n",
    "\n",
    "답변은 법조문을 인용하면서 구체적으로 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 비교용 - 기존 방식\n",
    "simple_prompt = f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요? 관련 정보: {context}\"\n",
    "\n",
    "print(\"\\n=== 개선된 프롬프트로 답변 ===\")\n",
    "response_improved = llm.invoke(improved_prompt)\n",
    "pprint(response_improved.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== 기존 프롬프트로 답변 ===\")\n",
    "response_simple = llm.invoke(simple_prompt)\n",
    "pprint(response_simple.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 추가 개선: 다른 검색 방식 시도\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== 검색 방식 개선 테스트 ===\")\n",
    "\n",
    "# MMR(Maximum Marginal Relevance) 검색 - 다양성 확보\n",
    "retriever_mmr = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 6, \"fetch_k\": 20}\n",
    ")\n",
    "retrieved_docs_mmr = retriever_mmr.invoke(query)\n",
    "context_mmr = \"\\n\\n\".join([f\"[문서 {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs_mmr)])\n",
    "\n",
    "response_mmr = llm.invoke(f\"\"\"\n",
    "{query}\n",
    "\n",
    "법령 조항 (MMR 검색):\n",
    "{context_mmr}\n",
    "\n",
    "위 법령을 바탕으로 비과세소득 항목들을 체계적으로 정리해주세요.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== MMR 검색 결과 ===\")\n",
    "pprint(response_mmr.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2691ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
