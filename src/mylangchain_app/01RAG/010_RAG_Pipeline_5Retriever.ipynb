{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1F5lTDp5UPf0",
   "metadata": {
    "id": "1F5lTDp5UPf0"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6"
   },
   "outputs": [],
   "source": [
    "# poetry add faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9abc5",
   "metadata": {},
   "source": [
    "##### Vector Store Retriever\n",
    "* 벡터 저장소(Vector Store)를 활용하여 사용자의 쿼리에 대한 가장 유사한 문서를 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 문서 리스트 생성\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain은 LLM 기반 애플리케이션을 쉽게 구축할 수 있도록 지원합니다.\"),\n",
    "    Document(page_content=\"벡터 저장소는 문서를 벡터화하여 빠른 검색을 가능하게 합니다.\"),\n",
    "    Document(page_content=\"멀티 쿼리 검색은 한 가지 질문을 여러 방식으로 변형하여 검색 효율을 높입니다.\"),\n",
    "    Document(page_content=\"LangChain은 해리슨 체이스(Harrison Chase)가 2022년 10월에 개발되었습니다.\"),\n",
    "    Document(page_content=\"LangChain의 주요 기능 중 하나는 다양한 LLM 모델과의 연동입니다.\"),\n",
    "    Document(page_content=\"LangChain Core 라이브러리는 기본 추상화 및 LangChain 표현 언어\"),\n",
    "    Document(page_content=\"LangChain Community 라이브러리는 서드파티 통합\"),\n",
    "]\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "#embedding_model = OpenAIEmbeddings()\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "\n",
    "# FAISS 기반 벡터 저장소 생성\n",
    "vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# search_kwargs의 기본값은 {\"k\": 3} 기본적으로 최대 3개의 문서를 검색\n",
    "# 필요에 따라 k 값을 조정하여 검색 문서 개수를 변경할 수 있음\n",
    "# search_kwargs={\"k\": 4}\n",
    "#retriever = vector_store.as_retriever()\n",
    "#print(type(retriever))\n",
    "\n",
    "filtered_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.3, \"k\": 4} # 임계값을 0.3으로 낮춤\n",
    ")\n",
    "\n",
    "# 검색 실행\n",
    "query = \"LangChain 이란?\"\n",
    "retrieved_docs = filtered_retriever.invoke(query)\n",
    "\n",
    "# 검색된 문서 출력\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c86e0f",
   "metadata": {},
   "source": [
    "##### Multi Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb70ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# 문서 리스트 생성\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain은 LLM 기반 애플리케이션을 쉽게 구축할 수 있도록 지원합니다.\"),\n",
    "    Document(page_content=\"벡터 저장소는 문서를 벡터화하여 빠른 검색을 가능하게 합니다.\"),\n",
    "    Document(page_content=\"멀티 쿼리 검색은 한 가지 질문을 여러 방식으로 변형하여 검색 효율을 높입니다.\"),\n",
    "    Document(page_content=\"LangChain은 해리슨 체이스(Harrison Chase)가 2022년 10월에 개발되었습니다.\"),\n",
    "    Document(page_content=\"LangChain의 주요 기능 중 하나는 다양한 LLM 모델과의 연동입니다.\"),\n",
    "    Document(page_content=\"LangChain Core 라이브러리는 기본 추상화 및 LangChain 표현 언어\"),\n",
    "    Document(page_content=\"LangChain Community 라이브러리는 서드파티 통합\"),\n",
    "]\n",
    "\n",
    "# 임베딩 및 벡터스토어 설정\n",
    "#embedding_model = OpenAIEmbeddings()\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# LLM 모델 설정 (GPT 사용)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",\n",
    "#     model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# Multi Query Retriever 생성\n",
    "retriever = MultiQueryRetriever.from_llm(retriever=filtered_retriever, llm=llm)\n",
    "\n",
    "# 검색 실행\n",
    "query = \"LangChain 이란?\"\n",
    "#query = \"오늘의 날씨는?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "print(len(retrieved_docs))\n",
    "\n",
    "# 검색된 문서 출력\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b74eb",
   "metadata": {},
   "source": [
    "##### VectorStoreRetriever 와 MultiQueryRetriever 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.schema import Document\n",
    "import logging\n",
    "\n",
    "# 로깅 설정 (쿼리 변형 과정 확인)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 문서 리스트 생성\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain은 LLM 기반 애플리케이션을 쉽게 구축할 수 있도록 지원합니다.\"),\n",
    "    Document(page_content=\"벡터 저장소는 문서를 벡터화하여 빠른 검색을 가능하게 합니다.\"),\n",
    "    Document(page_content=\"멀티 쿼리 검색은 한 가지 질문을 여러 방식으로 변형하여 검색 효율을 높입니다.\"),\n",
    "    Document(page_content=\"LangChain은 해리슨 체이스(Harrison Chase)가 2022년 10월에 개발되었습니다.\"),\n",
    "    Document(page_content=\"LangChain의 주요 기능 중 하나는 다양한 LLM 모델과의 연동입니다.\"),\n",
    "    Document(page_content=\"LangChain Core 라이브러리는 기본 추상화 및 LangChain 표현 언어\"),\n",
    "    Document(page_content=\"LangChain Community 라이브러리는 서드파티 통합\"),\n",
    "]\n",
    "\n",
    "# 임베딩 모델 및 벡터스토어 설정\n",
    "#embedding_model = OpenAIEmbeddings()\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# LLM 모델 설정 (GPT 사용)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",\n",
    "#     model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# 일반 VectorStore Retriever (기본 검색)\n",
    "vector_retriever = vector_store.as_retriever()\n",
    "\n",
    "# Multi Query Retriever 설정\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(retriever=vector_retriever, llm=llm)\n",
    "#multi_query_retriever = MultiQueryRetriever.from_llm(retriever=vector_store.as_retriever(search_kwargs={\"k\": 4}), llm=llm)\n",
    "\n",
    "# 검색 실행 (LangChain 관련 질문)\n",
    "query = \"LangChain 이란?\"\n",
    "\n",
    "print(\"\\n [1] 일반 VectorStore Retriever 검색 결과:\")\n",
    "retrieved_docs_vr = vector_retriever.invoke(query)\n",
    "for doc in retrieved_docs_vr:\n",
    "    print(f\" - {doc.page_content}\")\n",
    "\n",
    "print(\"\\n [2] Multi Query Retriever가 생성한 다양한 검색 쿼리:\")\n",
    "multi_query_retriever._log = True  # 변형된 쿼리 로깅 활성화\n",
    "retrieved_docs_mqr = multi_query_retriever.invoke(query)\n",
    "\n",
    "print(\"\\n [3] Multi Query Retriever 검색 결과:\")\n",
    "for doc in retrieved_docs_mqr:\n",
    "    print(f\" - {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d910ef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
